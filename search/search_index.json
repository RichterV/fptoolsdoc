{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Forest Py ToolsFP Tools features","text":"<p>Warning</p> <p>This library is under development, none of the presented solutions are available for download.</p> <p></p> <p>Process forest management end-to-end, easy as can be.</p> <p>With this library, you'll be able to plan forest inventories and volumetrics as well as process all data stemming from your forest plantation. FP Tools brings together various forestry processing methodologies into a single library, providing ease in model selection and forest performance analysis.</p> <p>This library was created as part of a master\u2019s project by student Vinicius Richter, aiming to facilitate the processing of forest inventory information and bridge the gap between IT professionals and forest engineers.</p> <p></p>"},{"location":"index.html#forest-inventory-planing-plots-alocation-on-qgis","title":"Forest inventory planing (plots alocation on QGIS)","text":"<p>In this module, you will be able to plan forest inventories by allocating plots with our plugin for QGIS.</p>"},{"location":"index.html#forest-inventory-planing","title":"Forest inventory planing","text":"<p>In this module, you will be able to plan forest inventories by allocating plots.</p>"},{"location":"index.html#hypsometric-relationship","title":"Hypsometric Relationship","text":"<p>In this module, you'll be able to perform the hypsometric relationship of a forest inventory using various equations as well as make use of artificial neural networks.</p>"},{"location":"index.html#volumetry","title":"Volumetry","text":"<p>In this module, you will be able to process tree volume data and fit volumetric and taper functions.</p>"},{"location":"index.html#assortments","title":"Assortments","text":"<p>In this module, you will be able to generate reports on the total volume and assortments produced by the forest.</p>"},{"location":"index.html#forest-report","title":"Forest Report","text":"<p>In this module, you will be able to generate a forest report at different levels based on the previous processing performed.</p>"},{"location":"index.html#clutter-forecast","title":"Clutter Forecast","text":"<p>In this module, you will be able to estimate future forest production using clutter model.</p>"},{"location":"index.html#ann-forecast","title":"ANN Forecast","text":"<p>In this module, you will be able to estimate future forest production using artificial neural networks.</p>"},{"location":"about_the_author.html","title":"About the Author","text":"Richter V. Bachelor\u2019s degree in Forestry Engineering and is currently pursuing a Master\u2019s degree in Forestry Engineering with a specialization in forest growth and production at the Federal University of Santa Maria. Works in the fields of artificial intelligence, computer vision, Python programming, forest inventory, remote sensing and forest management.  <p>    View portfolio </p>"},{"location":"ann_forecast.html","title":"ANN Forecast","text":"<p>Warning</p> <p>This library is under development, none of the presented solutions are available for download.</p> <p>Use continuous forest inventory databases to predict forest growth and production. Utilize artificial neural networks for greater flexibility. With this module, you will be able to estimate volume, the number of stems, basal area, among other variables of interest.</p>"},{"location":"ann_forecast.html#class-parameters","title":"Class Parameters","text":""},{"location":"ann_forecast.html#ann-trainer","title":"ANN Trainer","text":"<pre><code>AnnTrainer(df, y, *train_columns, iterator=None)\n</code></pre> Parameters Description df The dataframe containing the continous processed forest inventory data. y The target variable for training the ANN (Y), the variable on which the ANN will be trained to predict. *train_columns (<code>*args</code>) Names of the columns that will be used to train the artificial neural network so that it can predict the values of Y. Must be numeric. iterator (Optional) Name of the column that contains the <code>iterator</code>. An artificial neural network will be adjusted for each <code>iterator</code>."},{"location":"ann_forecast.html#class-functions","title":"Class Functions","text":"<p>functions and parameters<pre><code>  AnnTrainer.fit_model(save_dir=None)#(1)\n</code></pre></p> <ol> <li>save_dir = Directory where the <code>.pkl</code> ann file will be saved.</li> </ol> Parameters Description .fit_model() Adjust the model using <code>*train_columns</code> to predict the variable Y."},{"location":"ann_forecast.html#ann-structures","title":"Ann structures","text":"<p>6 different structures of artificial neural networks will be tested. Only the result from 1 model will be returned. The model returned will be selected by the ranking function. For the 'ann' model, the module sklearn.neural_network.MLPRegressor is used. --- title: ANN Parameters --- classDiagram     direction LR      class MLPRegressor {       Epochs: 3000       Activation: logistic       Solver Mode: lbfgs       Batch size: dynamic       Learning rate init: 0.1       Learning rate mode: adaptive     }      class Model-0 {       Hidden layer sizes: (15, 25, 20, 30, 10)     }     class Model-1 {       Hidden layer sizes: (35, 10, 25, 35, 15)      }     class Model-2 {       Hidden layer sizes: (25, 15, 30, 20)      }     class Model-3 {       Hidden layer sizes: (15, 35, 45)     }     class Model-4 {       Hidden layer sizes: (35, 10, 25, 35, 15)     }     class Model-5 {        Hidden layer sizes: (35, 10, 25, 35, 15, 20, 15, 30)     }       MLPRegressor &lt;|-- Model-0     MLPRegressor &lt;|-- Model-1     MLPRegressor &lt;|-- Model-2     MLPRegressor &lt;|-- Model-3     MLPRegressor &lt;|-- Model-4     MLPRegressor &lt;|-- Model-5</p>"},{"location":"ann_forecast.html#ann-predictor","title":"ANN Predictor","text":"<pre><code>AnnPredictor(pkl_file)\n</code></pre> Parameters Description pkl_file Directory of the <code>.pkl</code> file that will be used for prediction."},{"location":"ann_forecast.html#class-functions_1","title":"Class Functions","text":"<p>functions and parameters<pre><code>  AnnPredictor.predict(df, *args)#(1)\n</code></pre></p> <ol> <li>Returns the prediction of <code>Y</code> for the <code>*args</code> columns. The <code>*args</code> columns must be the same as those used in <code>*train_columns</code> for training.  </li> </ol>"},{"location":"ann_forecast.html#example-usage","title":"Example Usage","text":"<p>ann_forecast_example.py<pre><code>from fptools.forecast import AnnTrainer, AnnPredictor #(1)\nimport pandas as pd #(2)\n</code></pre></p> <ol> <li>Import <code>AnnTrainer</code> and <code>AnnPredictor</code> class.</li> <li>Import <code>pandas</code> for data manipulation.</li> </ol> <p>ann_forecast_example.py<pre><code>df_train = pd.read_csv(r'C:\\Your\\path\\continuous_inventory_data.csv') #(1)\ndf_predictions = pd.read_csv(r'C:\\Your\\path\\new_inventory_data.csv') #(2)\ncolumns_used_for_training = [\n                            \"age\",\n                            \"shafts\",\n                            \"basal-area\",\n                            \"HMAX\",\n                            \"DMAX\",\n                            \"DG\"\n                            ] #(3)\nann_train = AnnTrainer(df_train, y=\"commercial-volume\",\n                       *columns_used_for_training,\n                        iterator=\"Genetic Material\") #(4)\nann_train_metrics = ann_train.fit_model(\n                                        save_dir = r\"C:\\Your\\path\\output\") #(5)\n\n\nann_predictor = AnnPredictor(r\"C:\\Your\\path\\output\\comercial-volume_ann_predictor_GM-A.pkl\") #(6)\n\n\npredicted_commercial_volume = ann_predictor.predict(df_predictions, *columns_used_for_training) #(7)\n</code></pre></p> <ol> <li>Load your CSV file for training de ann.</li> <li>Load your CSV file for predictions.</li> <li>Create a list containing the names of the columns that will be used to predict Y. </li> <li>Create the variable <code>ann_train</code> containing the <code>AnnTrainer</code> class using the column <code>comercial-volume</code> as the <code>y</code>, the <code>columns_used_for_training</code> as <code>x</code> and the column <code>Genetic Material</code> as iterator.  </li> <li>Adjust the ann models, saving the <code>.pkl</code> files in the folder <code>C:\\Your\\path\\output</code>, and save the training metrics in the variable <code>ann_train_metrics</code>.  </li> <li>Load the adjusted model for <code>Genetic Material A</code> and save it in the variable <code>ann_predictor</code>.  </li> <li>Make predictions of <code>commercial-volume</code> using the columns <code>columns_used_for_training</code> from <code>df_predictions</code>.</li> </ol>"},{"location":"assortments.html","title":"Assortments","text":"<p>Warning</p> <p>This library is under development, none of the presented solutions are available for download.</p> <p>Obtain the products generated by the forest inventory based on a product table. Use fitted taper functions to estimate commercial and non-commercial volume generated by the forest. Estimate volumes using fitted volumetric equations.</p>"},{"location":"assortments.html#class-parameters","title":"Class Parameters","text":"<pre><code>Assortments(df, assortments_priority=None)\n</code></pre> Parameters Description df The dataframe containing the assortments data. assortments_priority (Optional) The name of the column who defines the assortments priority. If <code>None</code>, uses the default order from the dataframe."},{"location":"assortments.html#example-of-assortments-table","title":"Example of assortments table","text":"Product Length min (m) Length max (m) D min (cm) Loss (cm) Priority Prod. 1 10 10 12 0.5 1 Prod. 2 2 2 8 0.5 2 Prod. 3 1 1.5 2 0.5 3 <p>*The column order must be followed.</p>"},{"location":"assortments.html#class-functions","title":"Class Functions","text":"<p>functions and parameters<pre><code>  Assortments.get_assortments(model, model_path, trees_df, tree_dbh, tree_height,\n                              stump=0.1, initial_height=None) #(1)\n  Assortments.get_taper_volumes(model, model_path, trees_df, tree_dbh,\n                                tree_height, bark_factor=None, stump=0.1) #(2)\n  Assortments.get_volumes(model, model_path, trees_df, tree_dbh,\n                          tree_height, bark_factor=None) #(3)\n</code></pre></p> <ol> <li> <p>model = The name of the taper function or 'ann' to be used to calculate the assortments. model_path = Path to the <code>.json</code> file containing the coefficients of the fitted models or the <code>.pkl</code> file containing the fitted artificial neural network. trees_df = Pandas DataFrame containing the inventory for which the assortments should be calculated. tree_dbh = The name of the column containing the diameter at breast height (DBH) values in centimeters. tree_height = The name of the column containing the total height values of the trees in meters. stump = (Optional) Stump height value (meters) to be considered in the assortment calculation. If <code>stump==None</code>, it defaults to <code>0.1</code>. initial_height = (Optional) Height (meters) at which the products begin to be generated. Useful for cases where the base of the tree was damaged by fire or used for resin extraction.</p> </li> <li> <p>model = The name of the taper function or taper 'ann' to be used to calculate the volume. model_path = Path to the <code>.json</code> file containing the coefficients of the fitted models or the <code>.pkl</code> file containing the fitted artificial neural network. trees_df = Pandas DataFrame containing the inventory for which the volumes should be calculated. tree_dbh = The name of the column containing the diameter at breast height (DBH) values in centimeters. tree_height = The name of the column containing the total height values of the trees in meters. bark_factor = (Optional) Value of the bark factor to be used to calculate volumes without bark. stump = (Optional) Stump height value (meters) to be considered in the volumes calculation. If <code>stump==None</code>, it defaults to <code>0.1</code>.  </p> </li> <li> <p>model = The name of the volumetric function or volumetric 'ann' to be used to calculate the volume. model_path = Path to the <code>.json</code> file containing the coefficients of the fitted models or the <code>.pkl</code> file containing the fitted artificial neural network. trees_df = Pandas DataFrame containing the inventory for which the volumes should be calculated. tree_dbh = The name of the column containing the diameter at breast height (DBH) values in centimeters. tree_height = The name of the column containing the total height values of the trees in meters. bark_factor = (Optional) Value of the bark factor to be used to calculate volumes without bark.  </p> </li> </ol> Parameters Description .get_assortments() Returns the <code>trees_df</code> dataframe with additional columns indicating the number of products generated for each assortment, as well as the volume generated for each assortment in each tree. Calculates also the comercial volume, the total volume of the tree and also the wasted volume. .get_taper_volumes() Returns the <code>trees_df</code> with the volumes calculated based on the integration of taper functions. It calculates the total volume with bark and without bark. .get_volumes() Returns the <code>trees_df</code> with the volumes calculated based on the fitted volumetric functions. It calculates the total volume with bark and without bark."},{"location":"assortments.html#example-usage","title":"Example Usage","text":"<p>taper_functions_example.py<pre><code>from fptools.assortments import Assortments #(1)\nimport pandas as pd #(2)\n</code></pre></p> <ol> <li>Import <code>Assortments</code> class.</li> <li>Import <code>pandas</code> for data manipulation.</li> </ol> <p>Create a variable for the Volumetrics Class</p> <p>taper_functions_example.py<pre><code>assortments_df = pd.read_csv(r'C:\\Your\\path\\csv_tree_cubage_file.csv') #(1)\ninventory_df = pd.read_csv(r'C:\\Your\\path\\csv_tree_cubage_file.csv') #(2)\n\nProd = Assortments(assortments_df) #(3)\n\n\nassortments = Prod.get_assortments('kozak', r\"D:\\Your\\path\\for\\taper_functions_coefficients.json\",\n                                   inventory_df, \"DAP\", \"HT\") #(4)\ntaper_volumes = Prod.get_taper_volumes('bi', r\"D:\\Your\\path\\for\\taper_functions_coefficients.json\",\n                                       inventario, \"DAP\", \"HT\", .9) #(5)             \nvolumes = Prod.get_volumes('meyer', r\"D:\\Your\\path\\for\\taper_functions_coefficients.json\",\n                           inventario, \"DAP\", \"HT\", .85) #(6)\n</code></pre></p> <ol> <li>Load your assortments df from a csv file.</li> <li>Load your inventory df from a csv file.</li> <li>Create the variable <code>Prod</code> containing the <code>Assortments</code> class and using the <code>assortments_df</code> dataframe as products.</li> <li>Calculate assortments for each tree in the <code>inventory_df</code> using the <code>kozak</code> model, the <code>DAP</code> column for DBH values and the <code>HT</code> column for the tree height values.</li> <li>Calculate volumes with integration of <code>bi</code> function for each tree in the <code>inventory_df</code> using the <code>bi</code> model, the <code>DAP</code> column for DBH values and the <code>HT</code> column for the tree height values. Also uses a bark factor of <code>90%</code>.</li> <li>Calculate volumes with volumetric function for each tree in the <code>inventory_df</code> using the <code>meyer</code> model, the <code>DAP</code> column for DBH values and the <code>HT</code> column for the tree height values. Also uses a bark factor of <code>85%</code>.</li> </ol>"},{"location":"bug_report.html","title":"Bug Report","text":"<p>If you encountered any issues or would like to suggest an improvement, please feel free to access the bug report form. Your feedback helps us improve the tool.</p>"},{"location":"clutter_forecast.html","title":"Clutter Forecast","text":"<p>Warning</p> <p>This library is under development, none of the presented solutions are available for download.</p> <p>Use continuous forest inventory databases to predict forest growth and production. Utilize traditional method Clutter model. With this module, you will be able to estimate volume and basal area.</p>"},{"location":"clutter_forecast.html#class-parameters","title":"Class Parameters","text":""},{"location":"clutter_forecast.html#clutter-trainer","title":"Clutter Trainer","text":"<pre><code>ClutterTrainer(df, age1, age2, ba1, ba2, site, vol, iterator=None)\n</code></pre> Parameters Description df The dataframe containing the continous processed forest inventory data. age1 Name of the column containing the age of the previously sampled plot. age2 Name of the column containing the age of the subsequently sampled plot. ba1 Name of the column containing the basal area of the previously sampled plot. ba2 Name of the column containing the basal area of the subsequently sampled plot. site Name of the column containing the site index of the stand. vol Name of the column containing the volume of the subsequently sampled plot. iterator (Optional) Name of an iterator that will be used to group the data. Example of an iterator: Genetic material, Stratum."},{"location":"clutter_forecast.html#example-of-clutter-input","title":"Example of clutter input","text":"Iterator Plot age1 age2 ba1 ba2 site vol GM 1 1 2.5 3.5 7.57 8.42 7.83 44.04 GM 1 1 3.5 4.5 8.42 14 8.73 51.42 GM 1 2 2.1 3.1 4.94 5.51 6.98 38.06 GM 1 2 3.1 4.33 5.51 6.45 7.45 39.26 GM 2 1 2 3 7.3 8.25 11.37 74.63 GM 2 1 3 4 8.25 9.13 11.69 68.27 GM 2 1 4 5 9.13 12.79 12.83 72.76 GM 2 1 5 6 12.79 15.63 14 73.87"},{"location":"clutter_forecast.html#class-functions","title":"Class Functions","text":"<p>functions and parameters<pre><code>  ClutterTrainer.fit_model(save_dir=None)#(1)\n</code></pre></p> <ol> <li>save_dir = Directory where the coefficients and parameters of the trained models will be saved.</li> </ol> Parameters Description .fit_model() Adjust the models for predicting basal area and volume."},{"location":"clutter_forecast.html#clutter-models","title":"Clutter models","text":""},{"location":"clutter_forecast.html#basal-area-prediction","title":"<li>Basal area prediction</li>","text":"\\[ \\operatorname{lnb_2}^{\\text{est}} =b_0 + b_1 \\cdot x_1 + b_2 \\cdot x_2 + b_3 \\cdot x_3 + b_4 \\cdot \\frac{1}{I_2} + b_5 \\cdot S \\]"},{"location":"clutter_forecast.html#volume-prediction","title":"<li>Volume prediction</li>","text":"\\[ \\operatorname{lnv_2} = b_0 + b_1 \\cdot \\frac{1}{I_2} + b_2 \\cdot S + b_3 \\cdot \\operatorname{lnb_2}^{\\text{est} } \\]"},{"location":"clutter_forecast.html#notation","title":"Notation","text":"<ul> <li>\\( \u03b2_n \\): Fitted parameters</li> <li>\\( I \\): Age</li> <li> \\[\\operatorname{x_1} = \\ln(\u03b2_1) \\cdot \\frac{\\operatorname{I_1}}{\\operatorname{I}_2}\\] </li> <li> \\[\\operatorname{x_2} = 1 - \\frac{\\operatorname{I}_1}{\\operatorname{I}_2}\\] </li> <li> \\[\\operatorname{x_3} = \\left( 1 - \\frac{\\operatorname{I}_1}{\\operatorname{I}_2} \\right) \\cdot \\operatorname{S}\\] </li> <li>\\( S \\): Forest site</li> </ul>"},{"location":"clutter_forecast.html#class-parameters_1","title":"Class Parameters","text":""},{"location":"clutter_forecast.html#clutter-predictor","title":"Clutter Predictor","text":"<pre><code>ClutterPredictor(coefs_file, age1, site, ba1, iterator=None)\n</code></pre> Parameters Description coefs_file Directory of the <code>json</code> file containing the coefficients and parameters of the fitted models. age1 Name of the column containing the age of the previously sampled plot. ba1 Name of the column containing the basal area of the previously sampled plot. site Name of the column containing the site index of the stand. iterator (Optional) Name of an iterator that will be used for predictions."},{"location":"clutter_forecast.html#class-functions_1","title":"Class Functions","text":"<p>functions and parameters<pre><code>  ClutterTrainer.get_coefs()#(1)\n  ClutterTrainer.predict(age2)#(2)\n  ClutterTrainer.predict_range(age_range=(2, 10),show_plots=False)#(3)\n</code></pre></p> <ol> <li>Returns the loaded coefficients from <code>coefs_file</code>.  </li> <li>Returns the prediction made for <code>age2</code>.  </li> <li>Returns the prediction made for a specified age range in <code>age_range</code> as a tuple.    If <code>show_plots=True</code>, displays the plots of the performed predictions.  </li> </ol>"},{"location":"clutter_forecast.html#example-usage","title":"Example Usage","text":"<p>clutter_forecast_example.py<pre><code>fptools.forecast import ClutterTrainer, ClutterPredictor #(1)\nimport pandas as pd #(2)\n</code></pre></p> <ol> <li>Import <code>ClutterTrainer</code> and <code>ClutterPredictor</code> class.</li> <li>Import <code>pandas</code> for data manipulation.</li> </ol> <p>clutter_forecast_example.py<pre><code>df = pd.read_csv(r'C:\\Your\\path\\clutter_data.csv') #(1)\nc_train = ClutterTrainer(df,\"age-column1\",\"age-column2\", \"basal-area1\",\n                         \"basal-area1\",\"site-column\",\"volume-target\",\n                         iterator=\"Genetic Material\") #(2)\nc_train_metrics = c_train.fit_model(save_dir = r\"C:\\Your\\path\\output\") #(3)\n\n#\nc_predictor = ClutterPredictor(r\"C:\\Your\\path\\output\\all_coefficients.json\",\n                             2.35,9.27,9.13, iterator=\"type-x\") #(4)\n\nba_vol_predicted = c_predictor.predict(4) #(5)\ncoef = predictor.get_coefs() #(6)\nba_vol_range_predicted = predictor.predict_range((2,12), show_plots=True) #(7)\n</code></pre></p> <ol> <li>Load your CSV file.  </li> <li>Create the variable <code>c_train</code> containing the <code>ClutterTrainer</code> class.  </li> <li>Adjust the Clutter model, saving the coefficients and parameters in the folder <code>C:\\Your\\path\\output</code>, and save the training metrics in the variable <code>c_train_metrics</code>.  </li> <li>Create a variable containing the predictor. This predictor will use the saved model <code>C:\\Your\\path\\output\\all_coefficients.json</code> to apply an inventory with an age of <code>2.35</code>, a site index of <code>9.27</code>, and a basal area of <code>9.13</code> to predict future volume production and basal area.  </li> <li>Make the prediction for this plantation when it reaches <code>4</code> years old and save the results in <code>ba_vol_predicted</code>.  </li> <li>Obtain the model coefficients and save them in the variable <code>coef</code>.  </li> <li>Make the prediction for this plantation from <code>2</code> to <code>12</code> years, generating a graph showing the evolution of basal area and volume over this period, along with the confidence level.  </li> </ol>"},{"location":"clutter_forecast.html#example-of-output-prediction-plot","title":"Example of output prediction plot","text":""},{"location":"cubage_planning.html","title":"Cubage Planning","text":"<p>Warning</p> <p>This library is under development, none of the presented solutions are available for download.</p> <p>Use forest inventory data to plan the trees to be sampled for volume measurement, ensuring sufficient sampling of the plantation.</p>"},{"location":"cubage_planning.html#class-parameters","title":"Class Parameters","text":"<pre><code>CubagePlanning(df, tree_dbh, tree_height)\n</code></pre> Parameters Description df The DataFrame containing the tree data. tree_dbh The name of the column containing the diameter at breast height (DBH) values of the trees (centimeters). tree_height The name of the column that contains the total heights of the trees (meters)."},{"location":"cubage_planning.html#class-functions","title":"Class Functions","text":"functions and parameters<pre><code>  CubagePlanning.resume(n_classes=10, dbh_classes=None, height_classes=None,\n                        only_height_classes=False, only_dbh_classes=False)  #(1)\n  CubagePlanning.p_resume(n_classes=10, dbh_classes=None, height_classes=None,\n                          only_height_classes=False, only_dbh_classes=False)  #(2)\n  CubagePlanning.get_values(n_cubage_trees, n_classes=10, dbh_classes=None, height_classes=None,\n                            only_height_classes=False, only_dbh_classes=False) #(3)\n</code></pre> <ol> <li> <p>n_classes = Number of classes to which the values of height and diameter at breast height will be subjected.                                        dbh_classes = (Optional) Number of DBH classes to which the values of diameter at breast height will be subjected.  If <code>None</code>, uses <code>n_classes</code> value.   height_classes = (Optional) Number of height classes to which the values of height will be subjected.  If <code>None</code>, uses <code>n_classes</code> value.   only_height_classes = (Optional) If <code>True</code>, only height classes will be used for the summary. only_dbh_classes = (Optional) only DBH classes will be used for the summary.</p> </li> <li> <p>n_classes = Number of classes to which the values of height and diameter at breast height will be subjected.                                        dbh_classes = (Optional) Number of DBH classes to which the values of diameter at breast height will be subjected. If <code>None</code>, uses <code>n_classes</code> value.    height_classes = (Optional) Number of height classes to which the values of height will be subjected. If <code>None</code>, uses <code>n_classes</code> value.    only_height_classes = (Optional) If <code>True</code>, only height classes will be used for the summary. only_dbh_classes = (Optional) only DBH classes will be used for the summary.</p> </li> <li> <p>n_cubage_trees = Number of trees that will be selected for cubage. The default is 10.  n_classes = Number of classes to which the values of height and diameter at breast height will be subjected.                                        dbh_classes = (Optional) Number of DBH classes to which the values of diameter at breast height will be subjected. If <code>None</code>, uses <code>n_classes</code> value.   height_classes = (Optional) Number of height classes to which the values of height will be subjected.  If <code>None</code>, uses <code>n_classes</code> value.   only_height_classes = (Optional) If <code>True</code>, only height classes will be used for the summary. only_dbh_classes = (Optional) only DBH classes will be used for the summary.</p> </li> </ol> Parameters Description .resume() Returns a summary of how many trees from the provided dataframe are in each class. .p_resume() Returns a summary of the percentage of trees from the provided dataframe in each class. .get_values() Returns a dataframe indicating how many trees should be sampled for volume measurement in each class, based on the percentage representation of each class in the total inventory."},{"location":"cubage_planning.html#example-usage","title":"Example Usage","text":"<p>taper_functions_example.py<pre><code>from fptools.cubage_planning import CubagePlanning #(1)\nimport pandas as pd #(2)\n</code></pre></p> <ol> <li>Import <code>CubagePlanning</code> class.</li> <li>Import <code>pandas</code> for data manipulation.</li> </ol> <p>Create a variable for the Volumetrics Class</p> <p>taper_functions_example.py<pre><code>df = pd.read_csv(r'C:\\Your\\path\\csv_inventory_file.csv') #(1)\ncub = CubagePlanning(df ,'DAP','HT') #(2)\nresume = cub.resume() #(3)\npercentual_resume = cub.p_resume() #(4)\nresults = cub.get_values(n_cubage_trees=100) #(5)\n</code></pre></p> <ol> <li>Load your csv file.</li> <li>Create the variable <code>cub</code> containing the <code>CubagePlanning</code> class, using column <code>DAP</code> for the DBH values and the column <code>HT</code> for the heights values.</li> <li>Get a summary of how many trees from the provided dataframe are in each class and save on <code>resume</code> variable.</li> <li>Get a summary of the percentage of trees from the provided dataframe in each class and save on <code>percentual_resume</code> variable.</li> <li>Get a dataframe indicating how many trees should be sampled for volume measurement in each class, based on the percentage representation of each class in the total inventory and save on <code>results</code> variable.</li> </ol>"},{"location":"forest_report.html","title":"Forest Report","text":"<p>Warning</p> <p>This library is under development, none of the presented solutions are available for download.</p> <p>Generate a forest report based on estimated heights and volumes using the other modules of ForestPyTools. Obtain volume values and tree types per hectare at various specific levels of the forest stand, along with other metrics. Get the report in xlsx (Excel) or json format.</p>"},{"location":"forest_report.html#class-parameters","title":"Class Parameters","text":"<pre><code>ForestReport(df, plot_id, plot_size, tree_type, tree_dbh,\n             tree_height,group_levels = None, tree_vol_with_bark = None \n             tree_vol_withou_bark = None, iterator=None)\n</code></pre> Parameters Description df The dataframe containing the processed forest inventory data. plot_id Name of the column that contains the unique identifier for each plot. plot_size Numeric value indicating the plot size in square meters or the name of the column that contains the size of each plot in square meters. tree_type Name of the column that contains the <code>id</code> of the tree types present in the forest inventory. The <code>id</code> must be included in <code>tree_types_df</code>. tree_dbh Name of the column that contains the diameter at breast height (DBH) values. tree_height Name of the column that contains the tree height values. group_levels (Optional) List with the names of grouping levels that the user wants to create. A summary will be generated for each group. Example of groups: Farm, stand, soil type. tree_vol_with_bark (Optional) Name of the column that contains the tree volume values with bark. tree_vol_without_bark (Optional) Name of the column that contains the tree volume values without bark. iterator (Optional) Name of an iterator that will be used to group the data. Example of an iterator: Stratum."},{"location":"forest_report.html#class-functions","title":"Class Functions","text":"<p>functions and parameters<pre><code>  ForestReport.update_tree_types(df)#(1)\n  ForestReport.view_tree_types()#(2)\n  ForestReport.get_report(dir, format=\"xlsx\")#(3)\n</code></pre></p> <ol> <li>df = DataFrame containing the tree types present in the forest inventory. If <code>None</code>, the library's default DataFrame is used.</li> <li>dir = Directory where the report will be saved. format = Format in which the report will be saved. Could be <code>xlsx</code>(Excel) or <code>json</code>.</li> </ol> Parameters Description .update_tree_types() Updates the <code>tree_types_df</code> -&gt; DataFrame that contains the ids of tree types, names, and description. .view_tree_types() Displays the <code>tree_types_df</code> that the class is currently using. .get_report() Saves the forest report in <code>xlsx</code> or <code>json</code> format in the specified <code>dir</code>."},{"location":"forest_report.html#example-of-tree-types-table","title":"Example of tree types table","text":"ID Name Description Commercial Volume 0 normal Tree without significant distortions or defects 1 1 dead Dead tree 0 2 bifurcated adbh Bifurcated above the DBH 1 3 bifurcated bdbh Bifurcated below the DBH 1 4 burned Burned tree 0 <p>*The column order must be followed.</p>"},{"location":"forest_report.html#column-descriptions","title":"Column Descriptions","text":"<ul> <li> <p><code>id</code>: Represents a unique identifier for each type of tree in the classification. It is used to differentiate records and can serve as a key for reference in other datasets.</p> </li> <li> <p><code>name</code>: Indicates the name of the tree based on its condition or specific characteristics. This name acts as a short description for easy identification.</p> </li> <li> <p><code>description</code>: Provides a detailed explanation of the tree's condition, including information about its structure, health status, or possible defects that may affect its commercial quality.</p> </li> <li> <p><code>commercial_volume</code>: Defines whether the volume of this tree will be considered commercially usable. A value of <code>1</code> indicates that the tree has commercial volume and will be used, while <code>0</code> means its volume will not be utilized.</p> </li> </ul>"},{"location":"forest_report.html#example-usage","title":"Example Usage","text":"<p>forest_report_example.py<pre><code>from fptools.forest_report import ForestReport #(1)\nimport pandas as pd #(2)\n</code></pre></p> <ol> <li>Import <code>ForestReport</code> class.</li> <li>Import <code>pandas</code> for data manipulation.</li> </ol> <p>Create a variable for the ForestReport Class</p> <p>forest_report_example.py<pre><code>inventory_data = pd.read_csv(r'C:\\Your\\path\\processed_inventory.csv') #(1)\ntree_df_types = pd.read_csv(r'C:\\Your\\path\\tree_df_types.csv') #(2)\n\nReport = ForestReport(inventory_data,plot_id = \"plot_identifier\",plot_size = 'plot_size_column',\n                      tree_type='tree_type_tag', group_levels=['Farm', 'Stand'],\n                      tree_height=\"best_predicted_height (m)\", tree_dbh=\"DBH (cm)\",\n                      tree_vol_with_bark=\"Tree_volume\",tree_vol_without_bark= \"Tree_volume_no_bark\",\n                      iterator=\"forest stratum\")#(3)\nReport.view_tree_types()#(4)\n\nReport.update_tree_types(tree_df_types)#(5)\n\nReport.get_report(dir=r\"C:\\Users\\Desktop\", format=\"json\")#(6)\n</code></pre></p> <ol> <li>Load your procesed inventory data df from a csv file.</li> <li>Load your tree types df from a csv file.</li> <li>Create the variable <code>Report</code> containing the <code>ForestReport</code> class and using the <code>inventory_data</code> dataframe. Define the column <code>plot_identifier</code> as responsible for identifying each plot. Define the column <code>plot_size_column</code> as responsible for providing the plot size in square meters. Define the column <code>tree_type_tag</code> as responsible for identifying the ID of each tree present in <code>tree_types_df</code>. Define the columns <code>Farm</code> and <code>Stand</code> as sub-groups for which reports will be generated. Define the column <code>best_predicted_height (m)</code> as the column containing the tree heights in meters. Define the column <code>DBH (cm)</code> as the column containing the tree diameters at breast height in centimeters. Define the column <code>Tree_volume</code> as the column containing the total tree volume with bark. Define the column <code>Tree_volume_no_bark</code> as the column containing the total tree volume without bark. Define the column <code>forest stratum</code> as the main iterator in which the report will be generated.</li> <li>Show the <code>tree_types_df</code> in use.  </li> <li>Update the <code>tree_types_df</code> using the <code>tree_df_types</code> dataframe.  </li> <li>Save the report in <code>C:\\Users\\Desktop</code> as a <code>json</code> file.  </li> </ol>"},{"location":"getting_started.html","title":"Getting Started","text":"<p>Warning</p> <p>This library is under development, none of the presented solutions are available for download.</p> <p>To begin processing your forest data, as easily as possible, first install FP Tools.</p> <pre><code>pip install fptools\n</code></pre>"},{"location":"hypsometric_relationship.html","title":"Hypsometric Relationship","text":"<p>Warning</p> <p>This library is under development, none of the presented solutions are available for download.</p> <p>Estimate the heights of the missing trees based on the heights measured in the field.</p>"},{"location":"hypsometric_relationship.html#class-parameters","title":"Class Parameters","text":"<pre><code>HypRel(x, y, df, model, iterator)\n</code></pre> Parameters Description x The name of the column that contains the tree diameters/circumferences. y The name of the column that contains the tree heights. df The DataFrame containing the tree data. model (Optional) A list of models used for estimating tree heights. If none, will use all models avaliable. iterator (Optional) A column name string. Defines wich column will be used as a iterator. Could be a farm name, plot name, code or any unique identification tag."},{"location":"hypsometric_relationship.html#class-functions","title":"Class Functions","text":"<p>functions and parameters<pre><code>  HypRel.run()  \n  HypRel.view_metrics()  \n  HypRel.plots(dir = None, show = None) #(1) \n  HypRel.get_coef()\n  HypRel.predict()\n</code></pre></p> <ol> <li>dir = The directory you want to save your plots!      If <code>dir == None</code>, then the plots will be displayed. show = Display the plots on the screen! It can be <code>True</code> or <code>False</code>.</li> </ol> Parameters Description .run() Fit the models .view_metrics() Return a table of metrics of each evaluated model .plots(dir=None, show=True) Return the height and residuals plots .get_coef() Return the coefficients for each model .predict() Return the predict heights and used models in new columns"},{"location":"hypsometric_relationship.html#example-usage","title":"Example Usage","text":"<p>hyp_rel_example.py<pre><code>from fptools.hyp_rel import HypRel #(1)\nimport pandas as pd #(2)\n</code></pre></p> <ol> <li>Import <code>HypRel</code> class.</li> <li>Import <code>pandas</code> for data manipulation.</li> </ol> <p>Create a variable for the HypRel Class</p> <p>hyp_rel_example.py<pre><code>df = pd.read_csv(r'C:/Your/path/csv_inventory_file.csv') #(1)\nreg = HypRel('CAP',\"HT\",df) #(2)\nresults = reg.run() #(3) \nmetrics = reg.view_metrics() #(4) \nreg.plots(r'C:/Your/path/to_save',show=True) #(5) \ndf_coefficients =  reg.get_coef() #(6) \nfinal_results =  reg.predict() #(7) \n</code></pre></p> <ol> <li>Load your csv file.</li> <li>Create the variable <code>reg</code> containing the HypRel class.</li> <li>Run the models and save in the <code>results</code> variable.</li> <li>Evaluate the fitted models and save the metrics in the <code>metrics</code> variable.</li> <li>Generate the plots for the fitted models.</li> <li>Retrieve the coefficients for each fitted model.</li> <li>Obtain the final heights and the models used for estimation.</li> </ol> flowchart LR     subgraph run         runText1[Run all the available models]     end     subgraph metrics         runText2[Evaluate each fitted model]     end     subgraph plots         runText3[Generate plots]     end     subgraph coefficients         runText4[Return coefficients]     end     subgraph predict         runText5[Return the estimated heights and used functions]     end     %% Links para os subgr\u00e1ficos:     HypRel-Module --&gt; run     HypRel-Module --&gt; metrics     HypRel-Module --&gt; plots     HypRel-Module --&gt; coefficients     HypRel-Module --&gt; predict"},{"location":"hypsometric_relationship.html#available-models","title":"Available models","text":""},{"location":"hypsometric_relationship.html#curtis","title":"<li>curtis</li>","text":"\\[ \\operatorname{Total height} =e^{(\\beta_0+\u03b21*\\frac{1}{x})} \\]"},{"location":"hypsometric_relationship.html#parabolic","title":"<li>parabolic</li>","text":"\\[ \\operatorname{Total height} = \\beta_0 + \\beta_1 * x + \\beta_2 * x^2 \\]"},{"location":"hypsometric_relationship.html#stofels","title":"<li>stofels</li>","text":"\\[ \\operatorname{Total height} = e^{(\\beta_0+\\beta_1*\\ln(x))} \\]"},{"location":"hypsometric_relationship.html#henriksen","title":"<li>henriksen</li>","text":"\\[ \\operatorname{Total height} = \\beta_0 + \\beta_1 * \\ln(x) \\]"},{"location":"hypsometric_relationship.html#prodan_i","title":"<li>prodan_i</li>","text":"\\[ \\operatorname{Total height} = (\\frac{x^2}{\\beta_0+\\beta_1*x+\\beta_2* x^2}) \\]"},{"location":"hypsometric_relationship.html#prodan_ii","title":"<li>prodan_ii</li>","text":"\\[ \\operatorname{Total height} =(\\frac{x^2}{\\beta_0+\\beta_1*x+\\beta_2* x^2})+1.3 \\]"},{"location":"hypsometric_relationship.html#smd_fm","title":"<li>smd_fm</li>Transformations of YTransformations of X","text":"<p>Adaptation of the \"Forest Mensuration\" julia package by SILVA (2022), used to perform regressions using different types of transformations of diameter at breast height and height in hypsometric relationship processes.</p> <ul> <li> \\( y \\) </li> <li> \\( \\log(y) \\) </li> <li> \\( \\log(y - 1.3) \\) </li> <li> \\( \\log(1 + y) \\) </li> <li> \\( \\frac{1}{y} \\) </li> <li> \\( \\frac{1}{y - 1.3} \\) </li> <li> \\( \\frac{1}{\\sqrt{y}} \\) </li> <li> \\( \\frac{1}{\\sqrt{y - 1.3}} \\) </li> <li> \\( \\frac{x}{\\sqrt{y}} \\) </li> <li> \\( \\frac{x}{\\sqrt{y - 1.3}} \\) </li> <li> \\( \\frac{x^2}{y} \\) </li> <li> \\( \\frac{x^2}{y - 1.3} \\) </li> </ul> <ul> <li> \\( x \\) </li> <li> \\( x^2 \\) </li> <li> \\( \\log(x) \\) </li> <li> \\( \\log(x)^2 \\) </li> <li> \\( \\frac{1}{x} \\) </li> <li> \\( \\frac{1}{x^2} \\) </li> <li> \\( x + x^2 \\) </li> <li> \\( x + \\log(x) \\) </li> <li> \\( x + \\log(x)^2 \\) </li> <li> \\( x + \\frac{1}{x} \\) </li> <li> \\( x + \\frac{1}{x^2} \\) </li> <li> \\( x^2 + \\log(x) \\) </li> <li> \\( x^2 + \\log(x)^2 \\) </li> <li> \\( x^2 + \\frac{1}{x} \\) </li> <li> \\( \\log(x) + \\log(x)^2 \\) </li> <li> \\( \\log(x) + \\frac{1}{x} \\) </li> <li> \\( \\log(x) + \\frac{1}{x^2} \\) </li> <li> \\( \\log(x)^2 + \\frac{1}{x} \\) </li> <li> \\( \\log(x)^2 + \\frac{1}{x^2} \\) </li> <li> \\( \\frac{1}{x} + \\frac{1}{x^2} \\) </li> </ul>"},{"location":"hypsometric_relationship.html#ann","title":"<li>ann</li>","text":"<p>Explanation about ANN below.</p>"},{"location":"hypsometric_relationship.html#artificial-neural-network","title":"Artificial Neural Network","text":"<p>When selecting the 'ann' model, 4 different structures of artificial neural networks will be tested. Only the result from 1 model will be returned. The model returned will be selected by the ranking function. For the 'ann' model, the module sklearn.neural_network.MLPRegressor is used. --- title: ANN parameters --- classDiagram     class MLPRegressor {       Epochs: 3000       Activation: logistic       Solver Mode: lbfgs       Batch size: dynamic       Larning rate init: 0.1       Learning rate mode: adaptive     }      class Model-0 {       Hidden layer sizes: (4,5)     }     class Model_1 {       Hidden layer sizes: (4,2)     }     class Model_2 {       Hidden layer sizes: (3,2)     }     class Model_3 {       Hidden layer sizes: (4,4)     }      MLPRegressor &lt;|-- Model-0     MLPRegressor &lt;|-- Model_1     MLPRegressor &lt;|-- Model_2     MLPRegressor &lt;|-- Model_3</p>"},{"location":"hypsometric_relationship.html#ranking-function","title":"Ranking function","text":"<p>To select the best-performing models and rank them accordingly, the following metrics are obtained:</p> M\u00e9tric name Structure Mean Absolute Error (MAE) \\( MAE = \\frac{1}{n} \\sum_{i=1}^{n} \\|y_i - \\hat{y}_i\\| \\) Mean Absolute Percentage Error (MAPE) \\( MAPE = \\frac{100}{n} \\sum_{i=1}^{n} \\left\\|\\frac{y_i - \\hat{y}_i}{y_i}\\right\\| \\) Mean Squared Error (MSE) \\( MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \\) Root Mean Squared Error (RMSE) \\( RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} \\) R Squared (Coefficient of Determination) \\( R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} \\) Explained Variance (EV) \\( EV = 1 - \\frac{Var(y - \\hat{y})}{Var(y)} \\) Mean Error \\( Mean\\ Error = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i) \\) <p>After obtaining the metrics for each tested model, the best model receives a score of 10, while the others receive scores of 9, 8, and so on.</p>"},{"location":"plot_alocation.html","title":"Plot alocation","text":"<p>Warning</p> <p>This library is under development, none of the presented solutions are available for download.</p> <p>Allows the allocation of sampling plots with various types of sampling and plot formats. If you prefer a visual interface, consider using the QGIS module.</p>"},{"location":"plot_alocation.html#class-parameters","title":"Class Parameters","text":"<pre><code>PlotAlocation(shp_dir, epsg)\n</code></pre> Parameters Description shp_dir Directory of the shapefile defining the boundary of the area to be sampled. epsg The EPSG code of the shapefile defining the boundary of the area to be sampled."},{"location":"plot_alocation.html#class-functions","title":"Class Functions","text":"<p>functions and parameters<pre><code>PlotAlocation.create_plots(distribution, plot_format, plot_area, sample_number,\n                            by_hectare, min_border_distance, rectangle_size,\n                            x_y_angle, save_buffer, show_plot, save_dir)\n</code></pre></p> Parameter Description distribution Type of distribution or allocation that the plots should be subjected to. plot_format Format of the plot that will be installed. plot_area Area of the plot that will be installed. Not used when plot_format = 'rectangle' sample_number Could be the number of plots, the percentage of the total area that will be sampled or a column in the attribute table containing the number of plots per polygon. If value &lt; 1 it will be understood as a percentage. If value &gt;= 1 it will be understood that you are setting the quantity of plots to allocate. by_hectare If True, will use sample_number as plots per hectare. If sample_number &lt; 1, it will use the percentage only. min_border_distance Minimum distance in meters that the plots must be from the edge of the shapefile boundaries. rectangle_size Used when plot_format = 'rectangle'. Tuple containing the sizes of X and Y of the rectangle (x,y). x_y_angle Used when distribution = 'systematic custom'. Sets the distance in X and Y of each line in the grid of the systematic distribution and also the rotation angle in degrees (x,y,angle). save_buffer If true, saves the buffer considering the plot size around the point. show_plot If true, displays a figure of the allocation performed. save_dir Directory where the shapefiles will be saved. If None, no shapefile will be saved. <p>Available arguments</p> Type of distributionPlot formatEPSG <ul> <li><code>random</code> : Allocate the plots in a random distribution</li> <li><code>best sampling</code> : (recommended) Allocate the plots in the best possible distribution for the area considering the established parameters. </li> <li><code>systematic</code> : Allocate the plots in a grid distribution, does not allow the definition of <code>sample_number</code> and alocate all possible plots.</li> <li><code>systematic custom</code> : Allocate the plots in a grid distribution with the <code>x</code> and <code>y</code> distances from the grid lines and <code>grid rotation angle</code> defined by the user.</li> </ul> <ul> <li><code>round</code> : Consider that plots will have a rounded shape.</li> <li><code>squared</code> : Consider that plots will have a squared shape. </li> <li><code>rectangle</code> : Allows user to insert the X and Y sizes of the desired rectangle shape. </li> </ul> <ul> <li>In order to achieve the best precision in calculation, you must select the UTM zone that your area is in. Find your utm zone.</li> </ul>"},{"location":"plot_alocation.html#example-usage","title":"Example Usage","text":""},{"location":"plot_alocation.html#random-distribution","title":"Random distribution","text":"<p>plot_alocation_example_1.py<pre><code>from fptools.inventory_plots import PlotAlocation #(1)\nplots = PlotAlocation('example/shapefile/path.shp',epsg='32722') #(2)\nplots.create_plots(distribution=\"random\", sample_number=\"n_par\", plot_area=400,\n                    min_border_distance=20, save_dir=\"C:\\Users\\Desktop\",\n                    show_plot=True, save_buffer=True) #(3)\n</code></pre></p> <ol> <li>Import <code>PlotAlocation</code> class.  </li> <li>Create the <code>plots</code> variable with <code>PlotAlocation</code> class. Defines the boundary area shapefile path and the epsg.</li> <li>Create the plots with <code>random</code> distribuition, using \"n_par\" column on the atributte table  to define the number of plots, <code>plot area = 400 m\u00b2</code>, a minimum border distance of 20 meters and save the shapefile in <code>C:\\Users\\Desktop</code>.</li> </ol>"},{"location":"plot_alocation.html#systematic-custom-distribution","title":"Systematic custom distribution","text":"<p>plot_alocation_example_2.py<pre><code>from fptools.inventory_plots import PlotAlocation #(1)\nplots = PlotAlocation('example/shapefile/path.shp',epsg='32722') #(2)\nplots.create_plots(distribution=\"systematic custom\", x_y_angle=(100,50,45),\n                    plot_area=400, min_border_distance=20, save_dir=\"C:\\Users\\Desktop\",\n                    show_plot=True, save_buffer=True) #(3)\n</code></pre></p> <ol> <li>Import <code>PlotAlocation</code> class.  </li> <li>Create the <code>plots</code> variable with <code>PlotAlocation</code> class. Defines the boundary area shapefile path and the epsg.</li> <li>Create the plots with <code>systematic custom</code> distribuition, <code>plot area = 400 m\u00b2</code>, with <code>x distance = 100 meters</code>, <code>y distance = 50 meters</code> and 45\u00ba of grid rotation, with a minimum border distance of 20 meters and save the shapefile in <code>C:\\Users\\Desktop</code>.</li> </ol>"},{"location":"plot_alocation.html#rectangle-plot-format","title":"Rectangle plot format","text":"<p>plot_alocation_example_3.py<pre><code>from fptools.inventory_plots import PlotAlocation #(1)\nplots = PlotAlocation('example/shapefile/path.shp',epsg='32722') #(2)\nplots.create_plots(distribution=\"best sampling\", rectangle_size=(20,30), \n                    min_border_distance=20, save_dir=\"C:\\Users\\Desktop\",\n                    show_plot=True, save_buffer=True) #(3)\n</code></pre></p> <ol> <li>Import <code>PlotAlocation</code> class.  </li> <li>Create the <code>plots</code> variable with <code>PlotAlocation</code> class. Defines the boundary area shapefile path and the epsg.</li> <li>Create the plots with <code>best sampling</code> distribuition, a <code>rectangle width (x) = 20 meters</code> and <code>height (y) = 30 meters</code>, with a minimum border distance of 20 meters and save the shapefile in <code>C:\\Users\\Desktop</code>.</li> </ol>"},{"location":"plot_alocation_qgis.html","title":"Plot alocation with QGIS","text":"<p>With the FPT Plot Allocation Plugin, you will be able to allocate inventory plots using various sampling methods and plot shapes, all through a user-friendly and intuitive graphical interface.</p>"},{"location":"plot_alocation_qgis.html#plugin-instalation","title":"Plugin instalation","text":"<p>Within QGIS, go to \"Plugins\"  \"Manage and Install Plugins\" and search for \"FPT Plot Allocation\".</p>"},{"location":"plot_alocation_qgis.html#installation-via-zip-file","title":"Installation via zip file","text":"<p>If you prefer, click here to download the ZIP file containing the plugin files. For more information about installation, see the QGIS plugins installation guide.</p> To use FPTPlotAlocation, you must first install the scikit-learn package in the \"OSGeo4W Shell\" by running the command: \"pip install scikit-learn\"."},{"location":"plot_alocation_qgis.html#plugin-interface","title":"Plugin Interface","text":"This is the plugin interface. Below, you will learn how to configure and allocate your plots."},{"location":"plot_alocation_qgis.html#plugin-basics","title":"Plugin Basics","text":"Parameters Description Type of distribution Type of distribution of the plots. Plot format Format of the plot you want to install. Boundary layer The shapefile with the polygon of the area. Use a column to define plots number If selected, allows the user to choose a column to define the number of plots per polygon. Plot area Area in square meters that each plot will have. Sample numbers or sample percentage Could be the number of plots or the percentage of the total area that will be sampled. If <code>value &lt; 1</code> it will be understood as a percentage. If <code>value &gt;= 1</code> it will be understood that you are setting the quantity of plots to allocate. By hectare If selected, applies the value of <code>Sample numbers or sample percentage</code> per hectare. The value must be greater than 1. Minimum border distance (meters) (Optional) Defines the minimum distance in meters that each plot will have from the border. EPSG The EPSG of your area. Create buffer for plots (Optional) If checked, will create a buffer showing the area of the plots. Output (Optional) Select a folder to save your plots shapefile. <p>Available arguments</p> Type of distributionPlot formatEPSG <ul> <li><code>random</code> : Allocate the plots in a random distribution</li> <li><code>best sampling</code> : (recommended) Allocate the plots in the best possible distribution for the area considering the established parameters. </li> <li><code>systematic</code> : Allocate the plots in a grid distribution, does not allow the definition of <code>sample number or sample percentage</code> and alocate all possible plots.</li> <li><code>systematic custom</code> : Allocate the plots in a grid distribution with the <code>x</code> and <code>y</code> distances from the grid lines and <code>grid rotation angle</code> defined by the user.</li> </ul> <ul> <li><code>round</code> : Consider that plots will have a rounded shape.</li> <li><code>squared</code> : Consider that plots will have a squared shape. </li> <li><code>rectangle</code> : Allows user to insert the X and Y sizes of the desired rectangle shape. </li> </ul> <ul> <li>In order to achieve the best precision in calculation, you must select the UTM zone that your area is in. Find your utm zone.</li> </ul>"},{"location":"volumetry.html","title":"Volumetry","text":"<p>Warning</p> <p>This library is under development, none of the presented solutions are available for download.</p> <p>Process forest inventory data. Adjust volumetric equations and taper functions for later use.</p>"},{"location":"volumetry.html#class-parameters","title":"Class Parameters","text":"<pre><code>Volumetry(df, tree_identifier, tree_height, tree_dbh, tree_bark,\n            segment_height, segment_diameter, tree_bark)\n</code></pre> Parameters Description df The dataframe containing the cubage data. tree_identifier The name of the column that contains the unique identifiers of the trees. tree_height The name of the column that contains the total heights of the trees (meters). tree_dbh The name of the column containing the diameter at breast height (DBH) values of the trees (centimeters). tree_bark (Optional) The name of the column containing the bark thickness values of the trees (centimeters). If  <code>tree_bark == None</code>  return only volumes with bark on 'get_volumes()' method. segment_height (Optional) The name of the column containing the heights of the cubed segments of the trees (meters). Required for <code>fit_taper_functions()</code> method. segment_diameter (Optional) The name of the column containing the diameters of the cubed segments of the trees (centimeters). Required for <code>fit_taper_functions()</code> method. tree_bark (Optional) The name of the column containing tree bark (centimeters)."},{"location":"volumetry.html#class-functions","title":"Class Functions","text":"<p>functions and parameters<pre><code>  Volumetry.get_volumes()  \n  Volumetry.fit_taper_functions(models, iterator, save_dir = None)  #(1)\n  Volumetry.fit_volumetric_functions(models, iterator, vol_column,\n                                       save_dir = None) #(2)\n  Volumetry.get_individual_diameter(hi, tree_height, tree_dbh) #(3)\n  Volumetry.get_individual_taper_volume(tree_height, tree_dbh, stump=0.1) #(4)\n  Volumetry.get_individual_volume(tree_height, tree_dbh) #(5)\n</code></pre></p> <ol> <li>models = (Optional) List of models to be fitted! If <code>models == None</code> uses all available models.                                      iterator = (Optional) A column name string. Defines wich column will be used as a iterator. Could be a farm name, plot name, code or any unique identification tag. save_dir = (Optional) A directory to save the fitted function parameters and ann model.</li> <li>models = (Optional) List of models to be fitted! If <code>models == None</code> uses all available models.                                      iterator = (Optional) A column name string. Defines wich column will be used as a iterator. Could be a farm name, plot name, code or any unique identification tag.    vol_column = (Optional) A column name to the volume values. If <code>vol_column == None</code>, it uses de volumes obtained by the <code>get_volumes()</code> method to fit the volumetric functions. save_dir = (Optional) A directory to save the fitted function parameters and ann model.</li> <li>hi = Fraction of height from which you want to obtain the diameter (meters).                                      tree_height =  Total height of the tree (meters). tree_dbh = Diameter at breast height (DBH) value of the tree (centimeters).</li> <li>tree_height = Total height of the tree (meters).                                      tree_dbh = Diameter at breast height (DBH) of the tree (centimeters). stump = Stump height (meters). By default, uses <code>stump = 0.1</code>.  </li> <li>tree_height = Total height of the tree (meters).                                      tree_dbh = Diameter at breast height (DBH) of the tree (centimeters).  </li> </ol> Parameters Description .get_volumes() Returns the volume of each cubed segment and the total volume of each tree separated by <code>tree_identifier</code>. If <code>tree_bark == None</code>, it returns only the volume with bark; otherwise, it returns the volume with and without bark. .fit_taper_functions() Fits the available taper function models. Saves a <code>.json</code> file with the coefficients for each fitted model and a <code>.pkl</code> file for the fitted ANN's. .get_individual_diameter() Returns a pandas dataframe with diameter at a given <code>hi</code> height of the tree for each fitted taper model. .get_individual_taper_volume() Returns a pandas DataFrame with the estimated volume for the provided height and diameter at breast height for each fitted taper function. It uses the integration of taper functions to obtain the result. .get_individual_volume() Returns a pandas DataFrame with the estimated volume for the provided height and diameter at breast height for each fitted volumetric function."},{"location":"volumetry.html#example-usage","title":"Example Usage","text":"<p>taper_functions_example.py<pre><code>from fptools.fit_Volumetry import Volumetry #(1)\nimport pandas as pd #(2)\n</code></pre></p> <ol> <li>Import <code>Volumetry</code> class.</li> <li>Import <code>pandas</code> for data manipulation.</li> </ol> <p>Create a variable for the Volumetry Class</p> <p>taper_functions_example.py<pre><code>df = pd.read_csv(r'C:\\Your\\path\\csv_tree_cubage_file.csv') #(1)\nvol = Volumetry(df=df, tree_identifier='arvore_id', tree_height='HT', tree_dbh='DAP', segment_height='HT segmento', segment_diameter='Dsegmento',tree_bark='Casca') #(2)\ncalculated_volumes_df = vol.get_volumes() #(3) \nmetrics = vol.fit_taper_functions() #(4) \nvol.get_individual_diameter(1.3, 25, 30) #(5)\nvol.get_individual_taper_volume(30, 22.8) #(6)\nvol.get_individual_volume(30, 22.8) #(7)\n</code></pre></p> <ol> <li>Load your csv file.</li> <li>Create the variable <code>vol</code> containing the <code>Volumetry</code> class.</li> <li>Calculate volumes for each tree and segments em save the results on <code>calculated_volumes_df</code> variable.</li> <li>Fit the taper functions and save the performance metris in <code>metrics</code> variable. It will create a <code>.json</code> file with the models coefficients and a <code>.pkl</code> files for the fitted ann models.</li> <li>Get the diameter at 1.3 meters of a tree with a total height of 25 meters and a diameter at breast height (DBH) of 30 centimeters.</li> <li>Obtains the volumes calculated from the integration of taper functions for a tree with a height of 30 meters, a diameter at breast height of 22.8 centimeters, considering a stump height of 0.15 meters</li> <li>Obtains the volumes calculated from the fitted volumetric functions for a tree with a height of 30 meters and a diameter at breast height of 22.8 centimeters.</li> </ol>"},{"location":"volumetry.html#available-taper-models","title":"Available taper models","text":""},{"location":"volumetry.html#schoepfer","title":"<li>schoepfer</li>","text":"\\[ \\operatorname{d_i} =dbh\\left( b_0 + b_1 \\left( \\frac{h_i}{H} \\right) + b_2 \\left( \\frac{h_i}{H} \\right)^2 + b_3 \\left( \\frac{h_i}{H} \\right)^3 + b_4 \\left( \\frac{h_i}{H} \\right)^4 + b_5 \\left( \\frac{h_i}{H} \\right)^5 \\right) \\]"},{"location":"volumetry.html#bi","title":"<li>bi</li>","text":"\\[ \\operatorname{d_i}=dbh\\left[ \\left( \\frac{log\\;sin \\left( \\frac{\\pi}{2} \\frac{h_i}{H} \\right)} {log\\;sin \\left( \\frac{\\pi}{2} \\frac{1.3}{H} \\right)} \\right) ^{\\beta_0+\\beta_1sin\\left(\\frac{\\pi}{2}\\frac{h_i}{H}\\right)+\\beta_2sin\\left(\\frac{3\\pi}{2}\\frac{h_i}{H}\\right)+\\beta_3sin\\left(\\frac{\\pi}{2}\\frac{h_i}{H}\\right)/\\frac{h_i}{H}+\\beta_4dbh+\\beta_5\\frac{h_i}{H}\\sqrt{dbh}+\\beta_6\\frac{h_i}{H}\\sqrt{H}} \\right] \\]"},{"location":"volumetry.html#kozak","title":"<li>kozak</li>","text":"\\[ \\operatorname{d_i} =b_0 \\cdot (dbh^{b_1}) \\cdot (h^{b_2}) \\cdot \\left(\\frac{1 - \\left(\\frac{h_i}{h}\\right)^{1/4}}{1 - \\left(p^{1/3}\\right)}\\right)^{b_3 \\cdot \\left(\\frac{h_i}{h}\\right)^4 + b_4 \\cdot \\left(\\frac{1}{e^{dbh/h}}\\right) + b_5 \\cdot \\left(\\frac{1 - \\left(\\frac{h_i}{h}\\right)^{1/4}}{1 - \\left(p^{1/3}\\right)}\\right)^{0.1} + b_6 \\cdot \\left(\\frac{1}{dbh}\\right) + b_7 \\cdot \\left(h^{1 - \\left(\\frac{h_i}{h}\\right)^{1/3}}\\right) + b_8 \\cdot \\left(\\frac{1 - \\left(\\frac{h_i}{h}\\right)^{1/4}}{1 - \\left(p^{1/3}\\right)}\\right)} \\]"},{"location":"volumetry.html#johnson","title":"<li>johnson</li>","text":"\\[ \\operatorname{d_i} = dbh \\cdot \\left( b_0 \\cdot \\log\\left( \\frac{b_1 + \\frac{(H - h_i)}{(H - 1.3)}}{b_2} \\right) \\right) \\]"},{"location":"volumetry.html#matte","title":"<li>matte</li>","text":"\\[ \\operatorname{d_i} = dbh \\cdot \\left( b_0 \\cdot \\left( \\frac{H - h_i}{H - 1.30} \\right)^2 + b_1 \\cdot \\left( \\frac{H - h_i}{H - 1.30} \\right)^3 + b_2 \\cdot \\left( \\frac{H - h_i}{H - 1.30} \\right)^4 \\right) \\]"},{"location":"volumetry.html#ann","title":"<li>ann</li>","text":""},{"location":"volumetry.html#notation","title":"Notation","text":"<ul> <li>\\( \u03b2_n \\): Fitted parameters</li> <li>\\( d_i \\): Diameter (cm)</li> <li>\\( \\text{dbh} \\): Diameter at breast height (cm)</li> <li>\\( H \\): Total height (m)</li> <li>\\( h_i \\): Segment height (m)</li> </ul>"},{"location":"volumetry.html#artificial-neural-network","title":"Artificial Neural Network","text":"<p>When selecting the 'ann' model, 6 different structures of artificial neural networks will be tested. Only the result from 1 model will be returned. The model returned will be selected by the ranking function. For the 'ann' model, the module sklearn.neural_network.MLPRegressor is used. --- title: ANN Parameters --- classDiagram     direction LR      class MLPRegressor {       Epochs: 3000       Activation: logistic       Solver Mode: lbfgs       Batch size: dynamic       Learning rate init: 0.1       Learning rate mode: adaptive     }      class Model-0 {       Hidden layer sizes: (15, 25, 20, 30, 10)     }     class Model-1 {       Hidden layer sizes: (35, 10, 25, 35, 15)      }     class Model-2 {       Hidden layer sizes: (25, 15, 30, 20)      }     class Model-3 {       Hidden layer sizes: (15, 35, 45)     }     class Model-4 {       Hidden layer sizes: (35, 10, 25, 35, 15)     }     class Model-5 {        Hidden layer sizes: (35, 10, 25, 35, 15, 20, 15, 30)     }       MLPRegressor &lt;|-- Model-0     MLPRegressor &lt;|-- Model-1     MLPRegressor &lt;|-- Model-2     MLPRegressor &lt;|-- Model-3     MLPRegressor &lt;|-- Model-4     MLPRegressor &lt;|-- Model-5</p>"},{"location":"volumetry.html#available-volumetric-models","title":"Available volumetric models","text":""},{"location":"volumetry.html#spurr-model","title":"<li>Spurr Model</li>","text":"\\[ \\operatorname{V} = b_0 + b_1 \\cdot (\\text{dbh}^2) \\cdot H \\]"},{"location":"volumetry.html#schumacher-hall-model","title":"<li>Schumacher-Hall Model</li>","text":"\\[ \\operatorname{V} = b_0 \\cdot (\\text{dbh}^{b_1}) \\cdot (H^{b_2}) \\]"},{"location":"volumetry.html#honner-model","title":"<li>Honner Model</li>","text":"\\[ \\operatorname{V} = \\frac{\\text{dbh}^2}{b_1 \\cdot \\left(\\frac{1}{H}\\right)} \\]"},{"location":"volumetry.html#ogaya-model","title":"<li>Ogaya Model</li>","text":"\\[ \\operatorname{V} = \\frac{\\text{dbh}^2}{b_1 \\cdot H} \\]"},{"location":"volumetry.html#stoate-model","title":"<li>Stoate Model</li>","text":"\\[ \\operatorname{V} = b_0 + b_1 \\cdot \\text{dbh}^2 + b_2 \\cdot \\text{dbh}^2 \\cdot H + b_3 \\cdot H \\]"},{"location":"volumetry.html#naslund-model","title":"<li>Naslund Model</li>","text":"\\[ \\operatorname{V} = b_1 \\cdot \\text{dbh}^2 + b_2 \\cdot \\text{dbh}^2 \\cdot H + b_3 \\cdot \\text{dbh} \\cdot H^2 + b_4 \\cdot H^2 \\]"},{"location":"volumetry.html#takata-model","title":"<li>Takata Model</li>","text":"\\[ \\operatorname{V} = \\frac{\\text{dbh}^2 \\cdot H}{b_0 + b_1 \\cdot \\text{dbh}} \\]"},{"location":"volumetry.html#spurr-logarithmic-model","title":"<li>Spurr Logarithmic Model</li>","text":"\\[ \\operatorname{V} = \\exp(b_0 + b_1 \\cdot \\log(\\text{dbh}^2 \\cdot H)) \\]"},{"location":"volumetry.html#meyer-model","title":"<li>Meyer Model</li>","text":"\\[ \\operatorname{V} = b_0 + b_1 \\cdot \\text{dbh}^2 + b_2 \\cdot \\text{dbh} + b_3 \\cdot \\text{dbh} \\cdot H + b_4 \\cdot \\text{dbh}^2 \\cdot H \\]"},{"location":"volumetry.html#ann_1","title":"<li>ann</li>","text":"<p>Use the same ann models used for taper function.</p>"},{"location":"volumetry.html#notation_1","title":"Notation","text":"<ul> <li>\\( V \\): Estimated volume (m\u00b3)</li> <li>\\( \\text{dbh} \\): Diameter at breast height (cm)</li> <li>\\( H \\): Total height (m)</li> </ul>"},{"location":"volumetry.html#ranking-function","title":"Ranking function","text":"<p>To select the best-performing models and rank them accordingly, the following metrics are obtained:</p> M\u00e9tric name Structure Mean Absolute Error (MAE) \\( MAE = \\frac{1}{n} \\sum_{i=1}^{n} \\|y_i - \\hat{y}_i\\| \\) Mean Absolute Percentage Error (MAPE) \\( MAPE = \\frac{100}{n} \\sum_{i=1}^{n} \\left\\|\\frac{y_i - \\hat{y}_i}{y_i}\\right\\| \\) Mean Squared Error (MSE) \\( MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \\) Root Mean Squared Error (RMSE) \\( RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} \\) R Squared (Coefficient of Determination) \\( R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} \\) Explained Variance (EV) \\( EV = 1 - \\frac{Var(y - \\hat{y})}{Var(y)} \\) Mean Error \\( Mean\\ Error = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i) \\) <p>After obtaining the metrics for each tested model, the best model receives a score of 10, while the others receive scores of 9, 8, and so on.</p>"}]}